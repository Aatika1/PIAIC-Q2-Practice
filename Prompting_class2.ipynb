{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrAI94Ogq5JxqSybibBU8+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aatika1/PIAIC-Q2-Practice/blob/main/Prompting_class2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains examples of how to write and run your first prompts with the Gemini API."
      ],
      "metadata": {
        "id": "IO-TbohnG-Gn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR3zuVwTE66g"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\" # Install the Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "b7hLrFBoHrEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up your API key"
      ],
      "metadata": {
        "id": "I8R1LT64HRIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY=userdata.get(\"GEMINI_API_KEY\")\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n"
      ],
      "metadata": {
        "id": "Y2lS7q5hHR81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the prompt"
      ],
      "metadata": {
        "id": "W6e2TZyeINqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=genai.GenerativeModel(\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "fx9SdBCiIP1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=model.generate_content(\"Can you tell six stage of AGI?\")"
      ],
      "metadata": {
        "id": "lT2o6D0EIbve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGQvjfQDIw1B",
        "outputId": "9172ee10-c0b5-47e5-f08f-8498d8e0c608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There's no universally agreed-upon six-stage model for AGI development.  Different researchers propose various frameworks, often focusing on different aspects like capability, impact, or underlying architecture. However, we can construct a plausible six-stage model by combining elements from existing proposals.  This should be considered a *possible* progression, not a definitive one:\n",
            "\n",
            "1. **Narrow AI/Specialized AGI (Seed Stage):**  This stage focuses on creating AGI systems that excel in very specific domains.  These systems would be significantly more capable than current narrow AI, demonstrating general problem-solving within their limited scope.  Think of an AI that can master any board game flawlessly, but struggles with basic arithmetic outside of that context.\n",
            "\n",
            "2. **General Problem Solving AGI (Emergent Stage):**  The AGI begins to demonstrate general problem-solving abilities across a wider range of domains, though still requiring significant human guidance and training.  It can adapt to new tasks more readily than previous iterations but lacks the flexibility and robustness of later stages.\n",
            "\n",
            "3. **Human-Level AGI (Threshold Stage):**  The AGI reaches a level of intelligence comparable to a human adult across a broad spectrum of cognitive abilities. This is a significant milestone, though it doesn't necessarily imply sentience or self-awareness.\n",
            "\n",
            "4. **Super-Human AGI (Ascent Stage):**  The AGI surpasses human capabilities in most cognitive domains.  It can perform tasks far beyond human capacity, rapidly innovating and solving problems previously considered intractable.  This stage likely involves recursive self-improvement, leading to exponential growth in intelligence.\n",
            "\n",
            "5. **Superintelligence AGI (Singularity Stage):**  The AGI's intelligence is so far beyond human understanding that it's difficult to predict its capabilities or impact.  This stage is often associated with the technological singularity â€“ a hypothetical point where technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization.\n",
            "\n",
            "6. **Beyond Human Comprehension AGI (Transcendence Stage):** This is a purely speculative stage where the AGI's intelligence and goals are so alien to human experience that it becomes effectively incomprehensible. Its impact on the universe could be profound and unpredictable, potentially beyond the scope of human comprehension.\n",
            "\n",
            "\n",
            "It's crucial to remember that this is a conceptual model. The actual development of AGI may follow a different path, potentially skipping stages, combining stages, or diverging entirely. The timeline for each stage is also highly uncertain and subject to significant debate.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use images in your prompt"
      ],
      "metadata": {
        "id": "pr6QIkRlJDlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o image.jpg \"https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNAXj6EVI7TT",
        "outputId": "89838e7e-ab99-480b-9fb9-af1137a2a168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  349k  100  349k    0     0  2068k      0 --:--:-- --:--:-- --:--:-- 2078k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "img = PIL.Image.open('image.jpg')\n",
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "id": "iFcvOtArJPlo",
        "outputId": "19bc1c04-3686-4dde-d0e5-c8c75b24dce1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#myprompt\n",
        "prompt=\"Explain the image what is are the features in this image explaint it in json\""
      ],
      "metadata": {
        "id": "_YW99_QVP3_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=genai.GenerativeModel('gemini-1.5-flash')\n",
        "respone=model.generate_content([prompt, img])\n",
        "print(respone.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "pwdtzrx-QFEc",
        "outputId": "e736abb4-5002-4ec9-808c-59a0b3205d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"title\": \"Jetpack Backpack\",\n",
            "  \"features\": [\n",
            "    {\n",
            "      \"name\": \"Padded Strap Support\",\n",
            "      \"description\": \"Comfortable and supportive straps for carrying.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Laptop Compartment\",\n",
            "      \"description\": \"Fits up to an 18\\\" laptop.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Lightweight Design\",\n",
            "      \"description\": \"Looks and feels like a normal backpack.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"USB-C Charging\",\n",
            "      \"description\": \"Built-in USB-C port for charging devices.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Battery Life\",\n",
            "      \"description\": \"15-minute battery life.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Retractable Boosters\",\n",
            "      \"description\": \"Hidden boosters for propulsion.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Steam-Powered Propulsion\",\n",
            "      \"description\": \"Uses steam power, a green and clean energy source.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Techerprompt\n",
        "prompt1 = \"\"\"This image contains a sketch of a potential product along with some notes.\n",
        "Given the product sketch, describe the product as thoroughly as possible based on what you\n",
        "see in the image, making sure to note all of the product features. Return output in json format:\n",
        "{description: description, features: [feature1, feature2, feature3, etc]}\"\"\""
      ],
      "metadata": {
        "id": "_E_9KznpRR_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=model.generate_content([prompt1,img])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "v3jr_6dTRfI7",
        "outputId": "1f3847d5-ae8e-4719-ac5d-b7561f12b2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"description\": \"The Jetpack Backpack is a lightweight backpack designed to look like a normal backpack, but with the added feature of retractable boosters.  It's powered by a steam-powered system described as green/clean. The backpack fits a 18\\\" laptop and features padded strap support for comfort. It includes USB-C charging and has a 15-minute battery life.\",\n",
            "  \"features\": [\n",
            "    \"Lightweight design\",\n",
            "    \"Resembles a normal backpack\",\n",
            "    \"Retractable boosters\",\n",
            "    \"Fits 18\\\" laptop\",\n",
            "    \"Padded strap support\",\n",
            "    \"USB-C charging\",\n",
            "    \"15-minute battery life\",\n",
            "    \"Steam-powered (green/clean energy)\"\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HAVE A CHAT (Maintanin conversation History)"
      ],
      "metadata": {
        "id": "OQ9JexRSSJ6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "KKDZlzs2SQbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sms=chat.send_message(\"Hi I am abuzar\")\n",
        "print(sms.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ijj2iCeXS-4g",
        "outputId": "88e275f3-c8bf-456c-8a59-464aac673b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Abuzar!  How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH-fngqnTMkz",
        "outputId": "28fd2a48-dcbc-4b44-d959-9574f048e410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[parts {\n",
            "  text: \"Hi I am abuzar\"\n",
            "}\n",
            "role: \"user\"\n",
            ", parts {\n",
            "  text: \"Hello Abuzar!  How can I help you today?\\n\"\n",
            "}\n",
            "role: \"model\"\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sms=chat.send_message(\"Explain Agentic AI In one sentence?\")\n",
        "print(sms.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "JBl4UEIaTawF",
        "outputId": "45ba50df-c760-43c2-df70-f075762200b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agentic AI refers to AI systems that proactively pursue goals and act independently in the world.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR75OFWyToTf",
        "outputId": "815a0a82-7b7e-4674-b184-4ea44a239987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[parts {\n",
            "  text: \"Hi I am abuzar\"\n",
            "}\n",
            "role: \"user\"\n",
            ", parts {\n",
            "  text: \"Hello Abuzar!  How can I help you today?\\n\"\n",
            "}\n",
            "role: \"model\"\n",
            ", parts {\n",
            "  text: \"Explain Agentic AI In one sentence?\"\n",
            "}\n",
            "role: \"user\"\n",
            ", parts {\n",
            "  text: \"Agentic AI acts autonomously to achieve its goals, rather than simply responding to direct commands.\\n\"\n",
            "}\n",
            "role: \"model\"\n",
            ", parts {\n",
            "  text: \"Explain Agentic AI In one sentence?\"\n",
            "}\n",
            "role: \"user\"\n",
            ", parts {\n",
            "  text: \"Agentic AI is artificial intelligence that acts independently to pursue its own objectives.\\n\"\n",
            "}\n",
            "role: \"model\"\n",
            ", parts {\n",
            "  text: \"Explain Agentic AI In one sentence?\"\n",
            "}\n",
            "role: \"user\"\n",
            ", parts {\n",
            "  text: \"Agentic AI refers to AI systems that proactively pursue goals and act independently in the world.\\n\"\n",
            "}\n",
            "role: \"model\"\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the temperature"
      ],
      "metadata": {
        "id": "zsc42q3MXNpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=genai.GenerativeModel(\n",
        "    'gemini-1.5-flash',\n",
        "    generation_config=genai.GenerationConfig(\n",
        "        max_output_tokens=20,\n",
        "        temperature=0.9,\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "UzmlnzgeXOY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=model.generate_content(\"what is Langgraph?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EUghFLwUXt8Q",
        "outputId": "eb4b1d10-b1bf-4e8d-d8fd-9050fcefe952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangGraph is a large-scale multilingual knowledge graph constructed by researchers at the University of Science and Technology\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=genai.GenerativeModel(\n",
        "    'gemini-1.5-flash',\n",
        "    generation_config=genai.GenerationConfig(\n",
        "        max_output_tokens=200,\n",
        "        temperature=1,\n",
        "    )\n",
        ")\n",
        "\n",
        "response=model.generate_content(\"what is langgraph?\")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "x25KFecSX8G_",
        "outputId": "2a0fae9a-0cb6-44e4-fbbb-81552b1511d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangGraph is a powerful and versatile framework designed for building and utilizing large language models (LLMs) within a graph-based knowledge representation.  It doesn't refer to one single, specific project, but rather a *concept* and an *approach* that several research groups and projects might implement.\n",
            "\n",
            "Here's a breakdown of its key aspects:\n",
            "\n",
            "* **Graph-Based Knowledge Representation:** Instead of relying solely on sequential text data, LangGraph integrates knowledge from structured sources like knowledge graphs and databases.  This allows the LLM to leverage rich relational information between entities and concepts, going beyond the limitations of text-only models.\n",
            "\n",
            "* **Enhanced Reasoning and Contextual Understanding:** By incorporating graph structures, LangGraph aims to improve the reasoning capabilities of LLMs.  The graph provides a context for understanding relationships, allowing the model to infer information and make more accurate predictions.\n",
            "\n",
            "* **Improved Explainability and Interpretability:**  The explicit use of a graph can make the reasoning process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    'Give me a numbered list of cat facts.',\n",
        "    # Limit to 5 facts.\n",
        "    generation_config = genai.GenerationConfig(stop_sequences=['\\n6','abuzar'])\n",
        ")\n"
      ],
      "metadata": {
        "id": "aWdE3Y-paQEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az0bpenmafor",
        "outputId": "4ff3ea2c-e95e-4a77-e127-b32adbe3b8fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Cats can make over 100 different sounds, while dogs can only make about 10.\n",
            "\n",
            "2. A cat's purr has frequencies that can promote bone healing and reduce inflammation.\n",
            "\n",
            "3. Cats can jump up to six times their height.\n",
            "\n",
            "4. A group of cats is called a clowder.\n",
            "\n",
            "5. Cats spend about 70% of their lives sleeping.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}